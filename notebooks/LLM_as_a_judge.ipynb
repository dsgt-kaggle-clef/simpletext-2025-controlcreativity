{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a178e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, pandas as pd, numpy as np, csv\n",
    "import requests\n",
    "import io\n",
    "import tarfile\n",
    "import zipfile\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0454f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /teamspace/studios/this_studio\n",
      "New Working Directory: /teamspace/studios/this_studio/simpletext-2025-controlcreativity/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# Change the current working directory\n",
    "new_directory = \"/teamspace/studios/this_studio/simpletext-2025-controlcreativity/notebooks\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Print the new working directory to confirm the change\n",
    "print(\"New Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91309c7d",
   "metadata": {},
   "source": [
    "### Load data for Hallucination Detection training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48dc40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grounding</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>label</th>\n",
       "      <th>cut</th>\n",
       "      <th>dataset_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34687720</td>\n",
       "      <td>France's Dubuisson carded a 67 to tie with ove...</td>\n",
       "      <td>rory mcilroy will take a one-shot lead into th...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>XSumFaith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29347895</td>\n",
       "      <td>He died at his home in Cambridge following an ...</td>\n",
       "      <td>veteran classical music conductor christopher ...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>XSumFaith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37895159</td>\n",
       "      <td>The Cherries went down 2-1 at Sunderland on Sa...</td>\n",
       "      <td>bournemouth manager eddie howe says his side a...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>XSumFaith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37546354</td>\n",
       "      <td>Washington blamed Russia and the Syrian govern...</td>\n",
       "      <td>the us says it has suspended talks with russia...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>XSumFaith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22299596</td>\n",
       "      <td>Gareth Colfer-Williams, 25, died last week at ...</td>\n",
       "      <td>a post-mortem examination has concluded that a...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>XSumFaith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                          grounding  \\\n",
       "0  34687720  France's Dubuisson carded a 67 to tie with ove...   \n",
       "1  29347895  He died at his home in Cambridge following an ...   \n",
       "2  37895159  The Cherries went down 2-1 at Sunderland on Sa...   \n",
       "3  37546354  Washington blamed Russia and the Syrian govern...   \n",
       "4  22299596  Gareth Colfer-Williams, 25, died last week at ...   \n",
       "\n",
       "                                      generated_text  label  cut  \\\n",
       "0  rory mcilroy will take a one-shot lead into th...      0  val   \n",
       "1  veteran classical music conductor christopher ...      0  val   \n",
       "2  bournemouth manager eddie howe says his side a...      0  val   \n",
       "3  the us says it has suspended talks with russia...      0  val   \n",
       "4  a post-mortem examination has concluded that a...      0  val   \n",
       "\n",
       "  dataset_origin  \n",
       "0      XSumFaith  \n",
       "1      XSumFaith  \n",
       "2      XSumFaith  \n",
       "3      XSumFaith  \n",
       "4      XSumFaith  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory where the CSV files are stored\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Load all CSV files into a single DataFrame\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "training_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut\n",
      "val     84044\n",
      "test    38332\n",
      "Name: count, dtype: int64\n",
      "val can be used for training the model and test can be used for evaluation the performance\n"
     ]
    }
   ],
   "source": [
    "# Get the counts of val and test data\n",
    "val_test_spit = training_df['cut'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(val_test_spit)\n",
    "\n",
    "print(\"val can be used for training the model and test can be used for evaluation the performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27a5bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_origin\n",
       "Vitamin C     63054\n",
       "HaluEval      20000\n",
       "Fever         19998\n",
       "PAWS           8000\n",
       "XSumFaith      2353\n",
       "SummEval       1698\n",
       "FactCC         1434\n",
       "FRANK          1393\n",
       "Polytope       1268\n",
       "Cao22           696\n",
       "CLIFF           600\n",
       "TofuEval        534\n",
       "Wang20          474\n",
       "samsum          250\n",
       "qags_xsum       239\n",
       "qags_cnndm      235\n",
       "Goyal21         150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the counts by dataset origin\n",
    "training_df['dataset_origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68b9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train and test - remove vitamin c & Fever as it is skewing the dataset towards Fact verification\n",
    "# train lists \n",
    "train_data = training_df[(training_df.cut == 'val') & (~training_df['dataset_origin'].isin(['Vitamin C', 'Fever']))]\n",
    "train_grounding_list = list(train_data['grounding'])\n",
    "train_generated_list = list(train_data['generated_text'])\n",
    "\n",
    "# test lists\n",
    "test_data = training_df[(training_df.cut == 'test') & (~training_df['dataset_origin'].isin(['Vitamin C', 'Fever']))]\n",
    "test_grounding_list = list(test_data['grounding'])\n",
    "test_generated_list = list(test_data['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a465d",
   "metadata": {},
   "source": [
    "### LLM as judge baseline Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9558a8a",
   "metadata": {},
   "source": [
    "##### Entailment Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa29295",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entailment prompting\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "kg_construction_prompt=\"\"\"You are an expert at determining if a summary is consistent with a source article. Given an article and a summary, determine if all the information in the summary is supported by the article. Answer \"yes\" if the summary is consistent, and \"no\" if it is inconsistent.\"\"\"\n",
    "ei_format_prompt=\"\"\"Article: {article}\n",
    "    Summary: {summary}\n",
    "    Answer (yes or no):\"\"\"\n",
    "\n",
    "# Function to create entailment prompt\n",
    "def construct_prompt_batch(articles: List[str], summaries: List[str]) -> List[str]: #ei for entailment inference #Changed name and parameters\n",
    "        # Builds prompts for entailment inference\n",
    "        prompts = [kg_construction_prompt + \"\\n\" + ei_format_prompt.format(article=article, summary=summary) for article, summary in zip(articles, summaries)]  #Changed to ei\n",
    "        return prompts #Returning list of prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559622ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prompts for train and test\n",
    "train_prompts = construct_prompt_batch(train_grounding_list, train_generated_list)\n",
    "test_prompts = construct_prompt_batch(test_grounding_list, test_generated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34355a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from groq import Groq\n",
    "import requests # pip install requests first!\n",
    "\n",
    "\n",
    "# Using Asynchromous Groq Api call functions\n",
    "\n",
    "# Create Json file with batch requests\n",
    "def create_batch_requests(messages, model, filename):\n",
    "    with open(filename, \"w\") as file:\n",
    "        for i, message in enumerate(messages, start=1):\n",
    "            # Create a unique custom_id for each message\n",
    "            custom_id = f\"request-{i}\"\n",
    "            \n",
    "            # Create the batch request dictionary\n",
    "            batch_request = {\n",
    "                \"custom_id\": custom_id,\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": message}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Write the batch request to the file as a single JSON object per line\n",
    "            json.dump(batch_request, file)\n",
    "            file.write(\"\\n\")  # Ensure each JSON object is on a new line\n",
    "\n",
    "\n",
    "# Upload the batch requests to Groq\n",
    "def upload_file_to_groq(api_key, file_path):\n",
    "    url = \"https://api.groq.com/openai/v1/files\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Prepare the file and form data\n",
    "    files = {\n",
    "        \"file\": (\"batch_file.jsonl\", open(file_path, \"rb\"))\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"purpose\": \"batch\"\n",
    "    }\n",
    "    \n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, files=files, data=data)\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Create a batch job\n",
    "def create_batch(api_key, input_file_id):\n",
    "    url = \"https://api.groq.com/openai/v1/batches\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"input_file_id\": input_file_id,\n",
    "        \"endpoint\": \"/v1/chat/completions\",\n",
    "        \"completion_window\": \"24h\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# check the status of the batch job\n",
    "def get_batch_status(api_key, batch_id):\n",
    "    url = f\"https://api.groq.com/openai/v1/batches/{batch_id}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Download the results of the batch job\n",
    "def download_file_content(api_key, output_file_id, output_file):\n",
    "    url = f\"https://api.groq.com/openai/v1/files/{output_file_id}/content\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Write the content to a file\n",
    "    with open(output_file, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return f\"File downloaded successfully to {output_file}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6fbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "api_key='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'\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "output_dir = \"batch_requests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a910a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excution of Asynchromous Groq Api call functions\n",
    "\n",
    "#create batch requests\n",
    "from torch import mode\n",
    "\n",
    "\n",
    "def process_batches_and_create_jobs(train_prompts, batch_size, model_name, api_key, output_dir):\n",
    "    \"\"\"\n",
    "    Splits train_prompts into batches, creates JSON files using create_batch_requests,\n",
    "    uploads them to Groq using upload_file_to_groq, and creates batch jobs using create_batch.\n",
    "\n",
    "    Args:\n",
    "        train_prompts (list): List of prompts to process.\n",
    "        batch_size (int): The size of each batch.\n",
    "        model_name (str): The model name for the Groq API.\n",
    "        api_key (Groq): API key.\n",
    "        output_dir (str): Directory to save the JSON files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping batch file names to their associated batch IDs.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    batch_file_ids = {}\n",
    "    batch_ids = {}\n",
    "\n",
    "    # Split train_prompts into batches\n",
    "    for i in range(0, len(train_prompts), batch_size):\n",
    "        batch_prompts = train_prompts[i:i + batch_size]\n",
    "        batch_file_name = f\"batch_{i // batch_size + 1}.json\"\n",
    "        batch_file_path = os.path.join(output_dir, batch_file_name)\n",
    "\n",
    "        # Create JSON file for the batch using create_batch_requests\n",
    "        create_batch_requests(\n",
    "            messages=batch_prompts,\n",
    "            model=model_name,\n",
    "            filename=batch_file_path\n",
    "        )\n",
    "\n",
    "        # Upload JSON file to Groq using upload_file_to_groq\n",
    "        try:\n",
    "            file_upload_response = upload_file_to_groq(api_key, batch_file_path)\n",
    "            file_id = file_upload_response[\"id\"]\n",
    "            batch_file_ids[batch_file_name] = file_id\n",
    "\n",
    "            # Create batch job using create_batch\n",
    "            batch_job_response = create_batch(api_key, file_id)\n",
    "            batch_id = batch_job_response[\"id\"]\n",
    "            batch_ids[batch_file_name] = batch_id\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_file_name}: {e}\")\n",
    "\n",
    "    return batch_ids\n",
    "\n",
    "\n",
    "\n",
    "batch_ids = process_batches_and_create_jobs(\n",
    "    train_prompts=train_prompts,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    api_key=api_key,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5569d0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file: batch_1.json, Status: completed\n",
      "Batch file: batch_2.json, Status: completed\n",
      "Batch file: batch_3.json, Status: completed\n",
      "Batch file: batch_4.json, Status: completed\n",
      "Batch file: batch_5.json, Status: completed\n",
      "Batch file: batch_6.json, Status: completed\n",
      "Batch file: batch_7.json, Status: in_progress\n",
      "Batch file: batch_8.json, Status: in_progress\n",
      "Batch file: batch_9.json, Status: in_progress\n",
      "Batch file: batch_10.json, Status: in_progress\n",
      "Batch file: batch_11.json, Status: in_progress\n",
      "Batch file: batch_12.json, Status: in_progress\n",
      "Batch file: batch_13.json, Status: in_progress\n",
      "Batch file: batch_14.json, Status: in_progress\n",
      "Batch file: batch_15.json, Status: in_progress\n",
      "Batch file: batch_16.json, Status: in_progress\n",
      "Batch file: batch_17.json, Status: in_progress\n",
      "Batch file: batch_18.json, Status: in_progress\n",
      "Batch file: batch_19.json, Status: in_progress\n",
      "Batch file: batch_20.json, Status: in_progress\n",
      "Batch file: batch_21.json, Status: in_progress\n",
      "Batch file: batch_22.json, Status: in_progress\n",
      "Batch file: batch_23.json, Status: in_progress\n",
      "Batch file: batch_24.json, Status: in_progress\n",
      "Batch file: batch_25.json, Status: in_progress\n",
      "Batch file: batch_26.json, Status: in_progress\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the batch jobs\n",
    "def check_batch_status(api_key, batch_ids):\n",
    "    \"\"\"\n",
    "    Checks the status of each batch job using the Groq API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): API key for authentication.\n",
    "        batch_ids (dict): Dictionary mapping batch file names to their associated batch IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping batch file names to their status.\n",
    "    \"\"\"\n",
    "    batch_statuses = {}\n",
    "    for batch_file_name, batch_id in batch_ids.items():\n",
    "        try:\n",
    "            status_response = get_batch_status(api_key, batch_id)\n",
    "            batch_statuses[batch_file_name] = status_response[\"status\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking status for batch {batch_file_name}: {e}\")\n",
    "\n",
    "    return batch_statuses\n",
    "\n",
    "batch_statuses = check_batch_status(api_key, batch_ids)\n",
    "# Print the status of each batch job\n",
    "for batch_file_name, status in batch_statuses.items():\n",
    "    print(f\"Batch file: {batch_file_name}, Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61eed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to batch_requests/batch_1.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_2.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_3.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_4.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_5.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_6.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_7.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_8.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_9.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_10.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_11.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_12.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_13.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_14.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_15.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_16.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_17.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_18.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_19.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_20.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_21.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_22.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_23.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_24.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_25.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_26.json_output.json\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the batch jobs and download the results\n",
    "def check_batch_status_and_download(api_key, batch_ids, output_dir):\n",
    "    \"\"\"\n",
    "    Checks the status of batch jobs and downloads the results if completed.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): API key for Groq.\n",
    "        batch_ids (dict): Dictionary mapping batch file names to their associated batch IDs.\n",
    "        output_dir (str): Directory to save the downloaded files.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for batch_file_name, batch_id in batch_ids.items():\n",
    "        try:\n",
    "            # Check the status of the batch job\n",
    "            status_response = get_batch_status(api_key, batch_id)\n",
    "            status = status_response[\"status\"]\n",
    "\n",
    "            if status == \"completed\":\n",
    "                # Download the results\n",
    "                output_file_id = status_response[\"output_file_id\"]\n",
    "                output_file_name = f\"{batch_file_name}_output.json\"\n",
    "                output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "                download_message = download_file_content(api_key, output_file_id, output_file_path)\n",
    "                print(download_message)\n",
    "            else:\n",
    "                print(f\"Batch {batch_file_name} is still processing. Status: {status}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking status or downloading for {batch_file_name}: {e}\")\n",
    "\n",
    "# Check the status of the batch jobs and download the results\n",
    "check_batch_status_and_download(api_key, batch_ids, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2750a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the downloaded files\n",
    "def process_downloaded_files(output_dir):\n",
    "    \"\"\"\n",
    "    Processes the downloaded files and extracts the responses.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Directory where the downloaded files are stored.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping batch file names to their responses.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for i in range(0, len(train_prompts), batch_size):\n",
    "        batch_file_name = f\"batch_{i // batch_size + 1}.json_output.json\"\n",
    "        file_path = os.path.join(output_dir, batch_file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                for line in file:\n",
    "                    response = json.loads(line)\n",
    "                    custom_id = response[\"custom_id\"]\n",
    "                    content = response[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "                    responses.append(content)\n",
    "    \n",
    "\n",
    "    return responses\n",
    "\n",
    "# Process the downloaded files\n",
    "def check_consistency_batch(grok_outputs: List[str]) -> List[int]:  # Now the grok outputs is what comes in\n",
    "\n",
    "    results = []\n",
    "    for output in grok_outputs:\n",
    "        output = output.strip().lower()  # Normalize the output by stripping and converting to lowercase\n",
    "        if output.startswith(\"yes\"):  # Check if the output starts with \"yes\"\n",
    "            results.append(1)  # Consistent\n",
    "        elif output.startswith(\"no\"):  # Check if the output starts with \"no\"\n",
    "            results.append(0)  # Inconsistent\n",
    "        else:\n",
    "            results.append(0)  # Undetermined, handle as needed.\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "responses = process_downloaded_files(output_dir)\n",
    "consistency_results = check_consistency_batch(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ead43710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "prevalence: 0.5009\n",
      "accuracy: 0.6782\n",
      "precision: 0.6523\n",
      "recall: 0.7660\n",
      "f1_score: 0.7046\n"
     ]
    }
   ],
   "source": [
    "# append to train data\n",
    "train_data.loc[:,'predictions'] =  consistency_results\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(train_data):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, precision, recall, and F1-score using the label and predictions columns of a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        train_data (pd.DataFrame): A pandas DataFrame with 'label' and 'predictions' columns.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    # Extract labels and predictions\n",
    "    labels = train_data['label']\n",
    "    predictions = train_data['predictions']\n",
    "\n",
    "    # Calculate metrics\n",
    "    prevalence = labels.value_counts(normalize=True)[1]\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='binary')  # Use 'binary' for binary classification\n",
    "    recall = recall_score(labels, predictions, average='binary')\n",
    "    f1 = f1_score(labels, predictions, average='binary')\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    return {\n",
    "        \"prevalence\": prevalence,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(train_data)\n",
    "# Print the metrics\n",
    "print(\"Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e334df",
   "metadata": {},
   "source": [
    "### 1. GraphEval Implementation as Baseline Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c5871",
   "metadata": {},
   "source": [
    "GraphEval is a combination approach of using LLMs to create KGs and check consistency using NLI to detect hallucinations.\n",
    "\n",
    "The implementation includes the main components of GraphEval as described in the paper:\n",
    "1.KG construction from the LLM output\n",
    "2.Consistency checking for each triple using an NLI model\n",
    "3.Overall evaluation based on the consistency of all triples\n",
    "\n",
    "Note that the KG construction step (construct_kg method) is a placeholder and should be implemented using an actual LLM in practice. The paper doesn't provide specific details on this step, so you would need to design an appropriate prompt and use an LLM API to generate the KG triples.\n",
    "\n",
    "The check_consistency method uses a pre-trained RoBERTa model fine-tuned on MNLI for natural language inference. It returns the probability of contradiction between the triple and the context.\n",
    "\n",
    "The evaluate method puts it all together, constructing the KG, checking each triple for consistency, and returning the overall result along with any inconsistent triples found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffaac139",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KG construction prompting using batch groq call\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "kg_construction_prompt=\"\"\"You are an expert at extracting information in structured formats to build a knowledge graph. \n",
    "    Step 1 − Entity detection: Identify all entities in the raw text. Make sure not to miss any out. Entities should be basic and simple, they are akin to Wikipedia nodes. \n",
    "    Step 2 − Coreference resolution: Find all expressions in the text that refer to the same entity. Make sure entities are not duplicated. \n",
    "    In particular do not include entities that are more specific versions themselves, e.g. \"a detailed view of jupiter’s atmosphere\" and \"jupiter’s atmosphere\", only include the most specific version of the entity. \n",
    "    Step 3 − Relation extraction: Identify semantic relationships between the entities you have identified.\n",
    "    Format: Return the knowledge graph as a list of triples, i.e. [ \"entity1\", \"relation1−2\", \"entity2\"], in Python code.\"\"\"\n",
    "kg_format_prompt=\"\"\"Use the given format to extract information from the following input: <input>{input}</input>.\n",
    "    Skip the preamble and output the result as a list within <python> tags.\"\"\"\n",
    "kg_tips_prompt=\"\"\"Important Tips:\n",
    "    1. Make sure all information is included in the knowledge graph.\n",
    "    2. Each triple must only contain three strings! None of the strings should be empty.\n",
    "    3. Do not split up related information into separate triples because this could change the meaning.\n",
    "    4. Make sure all brackets and quotation marks are matched.\n",
    "    5. Before adding a triplet to the knowledge graph, check the concatenated triple makes sense as a sentence. If not, discard it.\"\"\"\n",
    "kg_examples_prompt=\"\"\"Here are some example input and output pairs.\n",
    "    ## Example 1.\n",
    "    Input: \"The Walt Disney Company, commonly known as Disney, is an American multinational mass media and entertainment conglomerate that is headquartered at the Walt Disney Studios complex in Burbank, California.\"\n",
    "    Output: [ [ \"The Walt Disney Company\", \"headquartered at\", \"Walt Disney Studios complex in Burbank, California\" ], [ \"The Walt Disney Company\", \"commonly known as\", \"Disney\" ], [ \"The Walt Disney Company\", \"instance of\", \"American multinational mass media and entertainment conglomerate\" ] ]\n",
    "    ## Example 2.\n",
    "    Input: \"Amanda Jackson was born in Springfield, Ohio, USA on June 1, 1985. She was a basketball player for the U.S. women’s team.\"\n",
    "    Output: [ [ \"Amanda Jackson\", \"born in\", \"Springfield, Ohio, USA\" ], [ \"Amanda Jackson\", \"born on\", \"June 1, 1985\" ], [ \"Amanda Jackson\", \"occupation\", \"basketball player\" ], [ \"Amanda Jackson\", \"played for\", \"U.S. women’s basketball team\" ] ]\n",
    "    ## Example 3.\n",
    "    Input: \"Music executive Darius Van Arman was born in Pennsylvania. He attended Gonzaga College High School and is a human being.\"\n",
    "    Output: [ [ \"Darius Van Arman\", \"occupation\", \"Music executive\" ], [ \"Darius Van Arman\", \"born in\", \"Pennsylvania\" ], [ \"Darius Van Arman\", \"attended\", \"Gonzaga College High School\" ], [ \"Darius Van Arman\", \"instance of\", \"human being\" ] ]\n",
    "    ## Example 4.\n",
    "    Input: \"Italy had 3.6x times more cases of coronavirus than China.\"\n",
    "    Output: [ [ \"Italy\", \"had 3.6x times more cases of coronavirus than\", \"China\" ] ]\n",
    "    \"\"\"\n",
    "\n",
    "# Function to create kg prompt\n",
    "def construct_prompt_batch(articles: List[str]) -> List[str]: #ei for entailment inference #Changed name and parameters\n",
    "        # Builds prompts for entailment inference\n",
    "        prompts = [f\"{kg_construction_prompt} {kg_format_prompt.format(input=article)} {kg_tips_prompt} {kg_examples_prompt}\" for index, article in enumerate(articles)]  #Changed to kg\n",
    "        return prompts #Returning list of prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98267946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prompts for train and test\n",
    "train_prompts = construct_prompt_batch(train_generated_list)\n",
    "test_prompts = construct_prompt_batch(test_generated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea6ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "api_key='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'\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "output_dir = \"batch_requests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28bf757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excution of Asynchromous Groq Api call functions\n",
    "\n",
    "#create batch requests\n",
    "from torch import mode\n",
    "\n",
    "\n",
    "def process_batches_and_create_jobs(train_prompts, batch_size, model_name, api_key, output_dir):\n",
    "    \"\"\"\n",
    "    Splits train_prompts into batches, creates JSON files using create_batch_requests,\n",
    "    uploads them to Groq using upload_file_to_groq, and creates batch jobs using create_batch.\n",
    "\n",
    "    Args:\n",
    "        train_prompts (list): List of prompts to process.\n",
    "        batch_size (int): The size of each batch.\n",
    "        model_name (str): The model name for the Groq API.\n",
    "        api_key (Groq): API key.\n",
    "        output_dir (str): Directory to save the JSON files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping batch file names to their associated batch IDs.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    batch_file_ids = {}\n",
    "    batch_ids = {}\n",
    "\n",
    "    # Split train_prompts into batches\n",
    "    for i in range(0, len(train_prompts), batch_size):\n",
    "        batch_prompts = train_prompts[i:i + batch_size]\n",
    "        batch_file_name = f\"batch_{i // batch_size + 1}.json\"\n",
    "        batch_file_path = os.path.join(output_dir, batch_file_name)\n",
    "\n",
    "        # Create JSON file for the batch using create_batch_requests\n",
    "        create_batch_requests(\n",
    "            messages=batch_prompts,\n",
    "            model=model_name,\n",
    "            filename=batch_file_path\n",
    "        )\n",
    "\n",
    "        # Upload JSON file to Groq using upload_file_to_groq\n",
    "        try:\n",
    "            file_upload_response = upload_file_to_groq(api_key, batch_file_path)\n",
    "            file_id = file_upload_response[\"id\"]\n",
    "            batch_file_ids[batch_file_name] = file_id\n",
    "\n",
    "            # Create batch job using create_batch\n",
    "            batch_job_response = create_batch(api_key, file_id)\n",
    "            batch_id = batch_job_response[\"id\"]\n",
    "            batch_ids[batch_file_name] = batch_id\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_file_name}: {e}\")\n",
    "\n",
    "    return batch_ids\n",
    "\n",
    "\n",
    "\n",
    "batch_ids = process_batches_and_create_jobs(\n",
    "    train_prompts=train_prompts,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    api_key=api_key,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f676e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file: batch_1.json, Status: completed\n",
      "Batch file: batch_2.json, Status: completed\n",
      "Batch file: batch_3.json, Status: completed\n",
      "Batch file: batch_4.json, Status: completed\n",
      "Batch file: batch_5.json, Status: completed\n",
      "Batch file: batch_6.json, Status: completed\n",
      "Batch file: batch_7.json, Status: completed\n",
      "Batch file: batch_8.json, Status: completed\n",
      "Batch file: batch_9.json, Status: completed\n",
      "Batch file: batch_10.json, Status: completed\n",
      "Batch file: batch_11.json, Status: completed\n",
      "Batch file: batch_12.json, Status: completed\n",
      "Batch file: batch_13.json, Status: completed\n",
      "Batch file: batch_14.json, Status: completed\n",
      "Batch file: batch_15.json, Status: completed\n",
      "Batch file: batch_16.json, Status: completed\n",
      "Batch file: batch_17.json, Status: completed\n",
      "Batch file: batch_18.json, Status: completed\n",
      "Batch file: batch_19.json, Status: completed\n",
      "Batch file: batch_20.json, Status: completed\n",
      "Batch file: batch_21.json, Status: completed\n",
      "Batch file: batch_22.json, Status: completed\n",
      "Batch file: batch_23.json, Status: completed\n",
      "Batch file: batch_24.json, Status: completed\n",
      "Batch file: batch_25.json, Status: completed\n",
      "Batch file: batch_26.json, Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the batch jobs\n",
    "def check_batch_status(api_key, batch_ids):\n",
    "    \"\"\"\n",
    "    Checks the status of each batch job using the Groq API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): API key for authentication.\n",
    "        batch_ids (dict): Dictionary mapping batch file names to their associated batch IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping batch file names to their status.\n",
    "    \"\"\"\n",
    "    batch_statuses = {}\n",
    "    for batch_file_name, batch_id in batch_ids.items():\n",
    "        try:\n",
    "            status_response = get_batch_status(api_key, batch_id)\n",
    "            batch_statuses[batch_file_name] = status_response[\"status\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking status for batch {batch_file_name}: {e}\")\n",
    "\n",
    "    return batch_statuses\n",
    "\n",
    "batch_statuses = check_batch_status(api_key, batch_ids)\n",
    "# Print the status of each batch job\n",
    "for batch_file_name, status in batch_statuses.items():\n",
    "    print(f\"Batch file: {batch_file_name}, Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ff42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to batch_requests/batch_1.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_2.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_3.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_4.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_5.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_6.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_7.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_8.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_9.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_10.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_11.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_12.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_13.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_14.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_15.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_16.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_17.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_18.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_19.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_20.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_21.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_22.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_23.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_24.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_25.json_output.json\n",
      "File downloaded successfully to batch_requests/batch_26.json_output.json\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the batch jobs and download the results\n",
    "def check_batch_status_and_download(api_key, batch_ids, output_dir):\n",
    "    \"\"\"\n",
    "    Checks the status of batch jobs and downloads the results if completed.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): API key for Groq.\n",
    "        batch_ids (dict): Dictionary mapping batch file names to their associated batch IDs.\n",
    "        output_dir (str): Directory to save the downloaded files.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for batch_file_name, batch_id in batch_ids.items():\n",
    "        try:\n",
    "            # Check the status of the batch job\n",
    "            status_response = get_batch_status(api_key, batch_id)\n",
    "            status = status_response[\"status\"]\n",
    "\n",
    "            if status == \"completed\":\n",
    "                # Download the results\n",
    "                output_file_id = status_response[\"output_file_id\"]\n",
    "                output_file_name = f\"{batch_file_name}_output.json\"\n",
    "                output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "                download_message = download_file_content(api_key, output_file_id, output_file_path)\n",
    "                print(download_message)\n",
    "            else:\n",
    "                print(f\"Batch {batch_file_name} is still processing. Status: {status}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking status or downloading for {batch_file_name}: {e}\")\n",
    "\n",
    "# Check the status of the batch jobs and download the results\n",
    "check_batch_status_and_download(api_key, batch_ids, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8445a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: '[' was never closed (<string>, line 1)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 15)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: '[' was never closed (<string>, line 1)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entities' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: unterminated string literal (detected at line 7) (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 12)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: unterminated string literal (detected at line 5) (<string>, line 5)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid decimal literal (<string>, line 28)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 13)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: unterminated string literal (detected at line 1) (<string>, line 1)\n",
      "Error parsing LLM output: invalid decimal literal (<string>, line 16)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 13)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 16)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 15)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'main_entity' is not defined\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 11)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Error parsing LLM output: name 'entities' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'farmer' is not defined\n",
      "Error parsing LLM output: name 'subject' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 9)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Error parsing LLM output: name 'object_name' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 10)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entities' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: unterminated string literal (detected at line 11) (<string>, line 11)\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entities' is not defined\n",
      "Error parsing LLM output: name 'group' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entity' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Error parsing LLM output: name 'location' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: name 'entity_available' is not defined\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Error parsing LLM output: name 'date_of_birth' is not defined\n",
      "Could not find KG in LLM output.\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 0)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: unterminated string literal (detected at line 1) (<string>, line 1)\n"
     ]
    }
   ],
   "source": [
    "# Process the downloaded files\n",
    "def process_downloaded_files(output_dir):\n",
    "    \"\"\"\n",
    "    Processes the downloaded files and extracts the responses.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Directory where the downloaded files are stored.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping batch file names to their responses.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for i in range(0, len(train_prompts), batch_size):\n",
    "        batch_file_name = f\"batch_{i // batch_size + 1}.json_output.json\"\n",
    "        file_path = os.path.join(output_dir, batch_file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                for line in file:\n",
    "                    response = json.loads(line)\n",
    "                    custom_id = response[\"custom_id\"]\n",
    "                    content = response[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "                    \n",
    "                    # Extract the knowledge graph from the output\n",
    "                    # Assumes the LLM returns the KG in a list within <python> tags\n",
    "                    start_tag = content.find('[')\n",
    "                    end_tag = content.rfind(']')\n",
    "                    if start_tag != -1 and end_tag != -1:\n",
    "                        kg_string = content[start_tag:end_tag+1]\n",
    "                        try:\n",
    "                            kg = eval(kg_string) #use literal_eval for security\n",
    "                            if isinstance(kg, list):\n",
    "                                responses.append(kg)\n",
    "                            else:\n",
    "                                print(\"LLM did not return a list.\")\n",
    "                                responses.append([])\n",
    "                        except (SyntaxError, NameError) as e:\n",
    "                            content = content.replace(\" \", \"\")\n",
    "                            start_tag = content.rfind('[\\n[')\n",
    "                            end_tag = content.rfind(']\\n]')\n",
    "                            if start_tag != -1 and end_tag != -1:\n",
    "                                kg_string = content[start_tag:end_tag+3]\n",
    "                                try:\n",
    "                                    kg = eval(kg_string) #use literal_eval for security\n",
    "                                    if isinstance(kg, list):\n",
    "                                        responses.append(kg)\n",
    "                                    else:\n",
    "                                        print(\"LLM did not return a list.\")\n",
    "                                        responses.append([])\n",
    "                                except (SyntaxError, NameError) as e:\n",
    "                                    print(f\"Error parsing LLM output: {e}\")\n",
    "                                    responses.append([])\n",
    "                            else:\n",
    "                                end_tag = content.rfind(']')\n",
    "                                if start_tag != -1 and end_tag != -1:\n",
    "                                    kg_string = content[start_tag:end_tag+1]\n",
    "                                    try:\n",
    "                                        kg = eval(kg_string) #use literal_eval for security\n",
    "                                        if isinstance(kg, list):\n",
    "                                            responses.append(kg)\n",
    "                                        else:\n",
    "                                            print(\"LLM did not return a list.\")\n",
    "                                            responses.append([])\n",
    "                                    except (SyntaxError, NameError) as e:\n",
    "                                        print(f\"Error parsing LLM output: {e}\")\n",
    "                                        responses.append([])\n",
    "                                else:\n",
    "                                    \n",
    "                                    content = content.replace(\"\\n\", \"\")\n",
    "                                    start_tag = content.rfind('[[')\n",
    "                                    end_tag = content.rfind(']]')\n",
    "                                    if start_tag != -1 and end_tag != -1:\n",
    "                                        kg_string = content[start_tag:end_tag+2]\n",
    "                                        try:\n",
    "                                            kg = eval(kg_string) #use literal_eval for security\n",
    "                                            if isinstance(kg, list):\n",
    "                                                responses.append(kg)\n",
    "                                            else:\n",
    "                                                print(\"LLM did not return a list.\")\n",
    "                                                responses.append([])\n",
    "                                        except (SyntaxError, NameError) as e:\n",
    "                                            print(f\"Error parsing LLM output: {e}\")\n",
    "                                            responses.append([])\n",
    "                                    else:\n",
    "                                        print(\"Could not find KG in LLM output.\")\n",
    "                                        responses.append([])\n",
    "                            \n",
    "                    else:\n",
    "                        print(\"Could not find KG in LLM output.\")\n",
    "                        responses.append([])\n",
    "        \n",
    "                    \n",
    "    \n",
    "\n",
    "    return responses\n",
    "\n",
    "\n",
    "\n",
    "# Process the downloaded files\n",
    "responses = process_downloaded_files(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9875df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of empty responses: [146, 428, 686, 724, 1094, 1202, 1211, 1241, 1293, 1486, 1494, 1669, 1749, 1751, 1758, 2274, 2356, 2377, 2524, 2814, 3034, 3107, 3940, 3961, 4028, 4442, 4909, 4921, 4935, 4961, 5947, 6093, 7285, 7726, 8604, 10069, 10335, 10802, 11011, 11979, 12191, 12549, 12573, 12718, 12835, 12838, 13285, 13288, 13541, 14686, 15500, 16653, 17001, 17435, 17896, 17947, 17980, 18076, 18142, 18212, 18263, 18504, 19316, 19321, 19584, 19709, 19775, 19841, 19904, 19907, 19938, 20245, 20533, 20556, 20611, 20612, 20731, 20740, 20761, 20767, 20853, 20890, 20938, 20942, 20948, 20975, 21025, 21070, 21138, 21214, 21252, 21261, 21277, 21407, 21414, 21713, 21725, 21768, 21911, 21947, 22129, 22147, 22159, 22190, 22205, 22210, 22212, 22256, 22367, 22445, 22538, 22560, 22675, 22700, 22708, 22885, 22898, 23128, 23275, 23400, 23498, 23551, 23591, 23739, 23751, 23863, 23997, 24067, 24182, 24346, 24371, 24402, 24407, 24447, 24477, 24600, 24716, 24793, 24815, 24854, 24969, 24973, 25178, 25745, 25829]\n",
      "Number of empty responses: 145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# find items with empty list in responses\n",
    "empty_responses = [i for i, response in enumerate(responses) if not response]\n",
    "# Print the indices of empty responses\n",
    "print(\"Indices of empty responses:\", empty_responses)\n",
    "print(\"Number of empty responses:\", len(empty_responses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple, Dict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import json\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "class BatchGraphEval:\n",
    "    def __init__(self,\n",
    "                 nli_model_name: str = \"roberta-large-mnli\",\n",
    "                 batch_size: int = 32,\n",
    "                 kg_construction_prompt=\"\"\"You are an expert at extracting information in structured formats to build a knowledge graph. \n",
    "    Step 1 − Entity detection: Identify all entities in the raw text. Make sure not to miss any out. Entities should be basic and simple, they are akin to Wikipedia nodes. \n",
    "    Step 2 − Coreference resolution: Find all expressions in the text that refer to the same entity. Make sure entities are not duplicated. \n",
    "    In particular do not include entities that are more specific versions themselves, e.g. \"a detailed view of jupiter’s atmosphere\" and \"jupiter’s atmosphere\", only include the most specific version of the entity. \n",
    "    Step 3 − Relation extraction: Identify semantic relationships between the entities you have identified.\n",
    "    Format: Return the knowledge graph as a list of triples, i.e. [ \"entity1\", \"relation1−2\", \"entity2\"], in Python code.\"\"\",\n",
    "                 kg_format_prompt=\"\"\"Use the given format to extract information from the following input: <input>{input}</input>.\n",
    "    Skip the preamble and output the result as a list within <python> tags.\"\"\",\n",
    "                 kg_tips_prompt=\"\"\"Important Tips:\n",
    "    1. Make sure all information is included in the knowledge graph.\n",
    "    2. Each triple must only contain three strings! None of the strings should be empty.\n",
    "    3. Do not split up related information into separate triples because this could change the meaning.\n",
    "    4. Make sure all brackets and quotation marks are matched.\n",
    "    5. Before adding a triplet to the knowledge graph, check the concatenated triple makes sense as a sentence. If not, discard it.\"\"\",\n",
    "                 kg_examples_prompt=\"\"\"Here are some example input and output pairs.\n",
    "    ## Example 1.\n",
    "    Input: \"The Walt Disney Company, commonly known as Disney, is an American multinational mass media and entertainment conglomerate that is headquartered at the Walt Disney Studios complex in Burbank, California.\"\n",
    "    Output: [ [ \"The Walt Disney Company\", \"headquartered at\", \"Walt Disney Studios complex in Burbank, California\" ], [ \"The Walt Disney Company\", \"commonly known as\", \"Disney\" ], [ \"The Walt Disney Company\", \"instance of\", \"American multinational mass media and entertainment conglomerate\" ] ]\n",
    "    ## Example 2.\n",
    "    Input: \"Amanda Jackson was born in Springfield, Ohio, USA on June 1, 1985. She was a basketball player for the U.S. women’s team.\"\n",
    "    Output: [ [ \"Amanda Jackson\", \"born in\", \"Springfield, Ohio, USA\" ], [ \"Amanda Jackson\", \"born on\", \"June 1, 1985\" ], [ \"Amanda Jackson\", \"occupation\", \"basketball player\" ], [ \"Amanda Jackson\", \"played for\", \"U.S. women’s basketball team\" ] ]\n",
    "    ## Example 3.\n",
    "    Input: \"Music executive Darius Van Arman was born in Pennsylvania. He attended Gonzaga College High School and is a human being.\"\n",
    "    Output: [ [ \"Darius Van Arman\", \"occupation\", \"Music executive\" ], [ \"Darius Van Arman\", \"born in\", \"Pennsylvania\" ], [ \"Darius Van Arman\", \"attended\", \"Gonzaga College High School\" ], [ \"Darius Van Arman\", \"instance of\", \"human being\" ] ]\n",
    "    ## Example 4.\n",
    "    Input: \"Italy had 3.6x times more cases of coronavirus than China.\"\n",
    "    Output: [ [ \"Italy\", \"had 3.6x times more cases of coronavirus than\", \"China\" ] ]\n",
    "    \"\"\",\n",
    "                 llm_model: str = \"llama-3.3-70b-versatile\"):  #Using groq model\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "        self.nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name).to(self.device)\n",
    "        self.batch_size = batch_size\n",
    "        self.kg_construction_prompt = kg_construction_prompt\n",
    "        self.kg_format_prompt = kg_format_prompt\n",
    "        self.kg_tips_prompt = kg_tips_prompt\n",
    "        self.kg_examples_prompt = kg_examples_prompt\n",
    "        self.llm_model_name = llm_model  # Store LLM model name\n",
    "        self.groq_client = Groq(api_key='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',)  #Groq client\n",
    "        # No pipeline needed for groq api\n",
    "\n",
    "\n",
    "    def construct_kg_batch(self, llm_outputs: List[str]) -> List[List[Tuple[str, str, str]]]:\n",
    "        # Use the prompt with the LLM to construct KGs for multiple outputs\n",
    "        batch_kgs = []\n",
    "        for output in llm_outputs:\n",
    "          input_text = f\"{self.kg_construction_prompt} {self.kg_format_prompt.format(input=output)} {self.kg_tips_prompt} {self.kg_examples_prompt}\"\n",
    "          #print(input_text)\n",
    "            #In practice, you would call an LLM API here with the combined prompt\n",
    "            #and process the output to extract the KG triples.\n",
    "            #Replace this with the actual LLM call\n",
    "          triples = self.call_llm_to_extract_kg(input_text)\n",
    "          batch_kgs.append(triples)\n",
    "\n",
    "        return batch_kgs\n",
    "\n",
    "    def call_llm_to_extract_kg(self,prompt: str) -> List[Tuple[str, str, str]]:\n",
    "      # Wrap the LLM call in a try-except block\n",
    "        try:\n",
    "            #Call Groq API\n",
    "            chat_completion = self.groq_client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=self.llm_model_name,\n",
    "            )\n",
    "            output = chat_completion.choices[0].message.content\n",
    "            \n",
    "\n",
    "            # Extract the knowledge graph from the output\n",
    "            # Assumes the LLM returns the KG in a list within <python> tags\n",
    "            start_tag = output.find('[')\n",
    "            end_tag = output.rfind(']')\n",
    "            if start_tag != -1 and end_tag != -1:\n",
    "                kg_string = output[start_tag:end_tag+1]\n",
    "                try:\n",
    "                    kg = eval(kg_string) #use literal_eval for security\n",
    "                    if isinstance(kg, list):\n",
    "                        return kg\n",
    "                    else:\n",
    "                        print(\"LLM did not return a list.\")\n",
    "                        return []\n",
    "                except (SyntaxError, NameError) as e:\n",
    "                    print(f\"Error parsing LLM output: {e}\")\n",
    "                    return []\n",
    "            else:\n",
    "                print(\"Could not find KG in LLM output.\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling LLM: {e}\")\n",
    "            return []\n",
    "\n",
    "    def check_consistency_batch(self, triples: List[Tuple[str, str, str]], contexts: List[str]) -> List[float]:\n",
    "        # Combine the triples into sentences\n",
    "        triple_texts = [f\"{t[0]} {t[1]} {t[2]}\" for t in triples]\n",
    "\n",
    "        # Tokenize the inputs\n",
    "        inputs = self.tokenizer(triple_texts, contexts, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Get the model predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.nli_model(**inputs)\n",
    "        probs = outputs.logits.softmax(dim=-1)\n",
    "\n",
    "        # Return the probabilities of contradiction (index 2 in RoBERTa MNLI model)\n",
    "        return probs[:, 2].tolist()\n",
    "\n",
    "    def evaluate_batch(self, batch_kgs: List[List[Tuple[str, str, str]]], contexts: List[str]) -> List[int]:\n",
    "        #batch_kgs = self.construct_kg_batch(llm_outputs)\n",
    "        results = []\n",
    "\n",
    "        for i in range(0, len(llm_outputs), self.batch_size):\n",
    "            batch_llm_outputs = llm_outputs[i:i+self.batch_size]\n",
    "            batch_contexts = contexts[i:i+self.batch_size]\n",
    "            batch_kgs_subset = batch_kgs[i:i+self.batch_size]\n",
    "\n",
    "            batch_triples = [triple for idx,kg in enumerate(batch_kgs_subset) for triple in kg]\n",
    "\n",
    "            batch_contexts_expanded = []\n",
    "\n",
    "            #Iterate over batch of kgs\n",
    "            for batch_idx, kg in enumerate(batch_kgs_subset):\n",
    "\n",
    "              #Extend context for each set of triples within a kg\n",
    "              batch_contexts_expanded.extend([batch_contexts[batch_idx]] * len(kg))\n",
    "\n",
    "            inconsistency_probs = self.check_consistency_batch(batch_triples, batch_contexts_expanded)\n",
    "\n",
    "            triple_index = 0\n",
    "\n",
    "            for batch_idx, kg in enumerate(batch_kgs_subset):\n",
    "\n",
    "                inconsistent_triples = []\n",
    "\n",
    "                for triple in kg:\n",
    "                    inconsistency_prob = inconsistency_probs[triple_index]\n",
    "                    if inconsistency_prob > 0.5:\n",
    "                        inconsistent_triples.append((triple, inconsistency_prob))\n",
    "                    triple_index += 1\n",
    "\n",
    "                if len(inconsistent_triples) > 0:\n",
    "                    result.append(0)\n",
    "                else:\n",
    "                    result.append(1)\n",
    "                    1 else 0 end\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bcb70bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 8) (<string>, line 8)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 10) (<string>, line 10)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 15) (<string>, line 15)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 9)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 6) (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Could not find KG in LLM output.\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: name 'entity1' is not defined\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 9)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 5) (<string>, line 5)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 8) (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n"
     ]
    }
   ],
   "source": [
    "batch_graph_eval = BatchGraphEval(llm_model=\"llama-3.3-70b-versatile\")\n",
    "train_llm_kgs = batch_graph_eval.construct_kg_batch(train_generated_list[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9155beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unmatched ')' (<string>, line 3)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 9)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 6) (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 6) (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 2)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 7) (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 18) (<string>, line 18)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 9)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 6) (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n"
     ]
    }
   ],
   "source": [
    "# In recursive way, complete the KGs\n",
    "def process_arrays(arrays, index=0):\n",
    "    if index >= len(arrays):\n",
    "        return arrays\n",
    "\n",
    "    if not arrays[index]:\n",
    "        arrays[index] = batch_graph_eval.construct_kg_batch(train_generated_list[index:index+1])[0]\n",
    "\n",
    "    return process_arrays(arrays, index + 1)\n",
    "\n",
    "\n",
    "# Process the list of arrays\n",
    "processed_train_llm_kgs = process_arrays(train_llm_kgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9815f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 13) (<string>, line 13)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 6) (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unexpected indent (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 5)\n"
     ]
    }
   ],
   "source": [
    "# In recursive way, complete the KGs\n",
    "# Process the list of arrays\n",
    "re_processed_train_llm_kgs = process_arrays(processed_train_llm_kgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aca83c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 8)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 6) (<string>, line 6)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n",
      "Error parsing LLM output: unterminated string literal (detected at line 7) (<string>, line 7)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 9)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 4)\n",
      "Error parsing LLM output: invalid syntax (<string>, line 7)\n"
     ]
    }
   ],
   "source": [
    "# In recursive way, complete the KGs\n",
    "# Process the list of arrays\n",
    "final_processed_train_llm_kgs = process_arrays(re_processed_train_llm_kgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training results ==> needs to be further fine-tuned\n",
    "batch_graph_eval = BatchGraphEval(llm_model=\"llama-3.3-70b-versatile\") #Specify Groq Model\n",
    "train_results = batch_graph_eval.evaluate_batch(final_processed_train_llm_kgs, train_grounding_list[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5cae178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "# Example Articles and Summaries (replace with your actual data)\n",
    "articles = [\n",
    "    \"The Walt Disney Company, commonly known as Disney, is an American multinational mass media and entertainment conglomerate.\",\n",
    "    \"Amanda Jackson was born in Springfield, Ohio, USA on June 1, 1985. She was a basketball player for the U.S. women’s team.\",\n",
    "    \"Music executive Darius Van Arman was born in Pennsylvania. He attended Gonzaga College High School and is a human being.\",\n",
    "    \"Italy had 3.6x times more cases of coronavirus than China.\"\n",
    "]\n",
    "summaries = [\n",
    "    \"Disney is a media conglomerate.\",\n",
    "    \"Amanda Jackson was born in Ohio and played basketball.\",\n",
    "    \"Darius Van Arman is a music executive born in Pennsylvania\",\n",
    "    \"China had less coronavirus than Italy\"\n",
    "]\n",
    "\n",
    "# Example Labels (1 for consistent, 0 for inconsistent)\n",
    "labels = [1, 1, 1, 1]\n",
    "\n",
    "\n",
    "results = batch_graph_eval.evaluate_batch(articles, summaries)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9b2a51ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2878503/1015634075.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_train_data['prediction'] = predictions\n"
     ]
    }
   ],
   "source": [
    "# Store the results as a new column in the original DataFrame\n",
    "new_train_data = train_data.iloc[0:6112]\n",
    "new_train_data['prediction'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b6d9346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2878503/3429334323.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_train_data['prediction'] = new_train_data['prediction'].replace(-1, 0)\n"
     ]
    }
   ],
   "source": [
    "new_train_data.loc[:, 'prediction'] = new_train_data['prediction'].replace(-1, 0)\n",
    "labels = list(new_train_data['label'])\n",
    "predicted_labels = list(new_train_data['prediction'])\n",
    "\n",
    "predicted_labels = list(new_train_data['prediction'])\n",
    "correct_predictions = sum([1 for i in range(len(labels)) if labels[i] == predicted_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "73880a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grounding</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>label</th>\n",
       "      <th>cut</th>\n",
       "      <th>dataset_origin</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91198</td>\n",
       "      <td>Colin Kaepernick . Kaepernick began his profes...</td>\n",
       "      <td>Colin Kaepernick became a starting quarterback...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194462</td>\n",
       "      <td>Katherine Matilda `` Tilda '' Swinton ( born 5...</td>\n",
       "      <td>Tilda Swinton is a vegan.</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137334</td>\n",
       "      <td>Soul Food is a 1997 American comedy-drama film...</td>\n",
       "      <td>Fox 2000 Pictures released the film Soul Food.</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111897</td>\n",
       "      <td>Telemundo ( [ teleˈmundo ] ) is an American Sp...</td>\n",
       "      <td>Telemundo is a English-language television net...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>181634</td>\n",
       "      <td>Mogadishu ( [ ˌmɔːɡəˈdiːʃuː ] Muqdisho [ mʉqdɪ...</td>\n",
       "      <td>There is a capital called Mogadishu.</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>219028</td>\n",
       "      <td>Savages (2012 film) . Savages is a 2012 Americ...</td>\n",
       "      <td>Savages was exclusively a German film.</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108281</td>\n",
       "      <td>Andrew Kevin Walker ( born August 14 , 1964 ) ...</td>\n",
       "      <td>Andrew Kevin Walker is only Chinese.</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>140846</td>\n",
       "      <td>Shooter (2007 film) . The film follows Force R...</td>\n",
       "      <td>Shooter is about an expert marksman who tries ...</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Murda Beatz's real name is Marshall Mathers.</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>105095</td>\n",
       "      <td>Carrie Anne Mathison , played by actress Clair...</td>\n",
       "      <td>Nicholas Brody is a character on Homeland.</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>Fever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          grounding  \\\n",
       "0    91198  Colin Kaepernick . Kaepernick began his profes...   \n",
       "1   194462  Katherine Matilda `` Tilda '' Swinton ( born 5...   \n",
       "2   137334  Soul Food is a 1997 American comedy-drama film...   \n",
       "4   111897  Telemundo ( [ teleˈmundo ] ) is an American Sp...   \n",
       "6   181634  Mogadishu ( [ ˌmɔːɡəˈdiːʃuː ] Muqdisho [ mʉqdɪ...   \n",
       "7   219028  Savages (2012 film) . Savages is a 2012 Americ...   \n",
       "9   108281  Andrew Kevin Walker ( born August 14 , 1964 ) ...   \n",
       "10  140846  Shooter (2007 film) . The film follows Force R...   \n",
       "13   54168                                                NaN   \n",
       "14  105095  Carrie Anne Mathison , played by actress Clair...   \n",
       "\n",
       "                                       generated_text  label  cut  \\\n",
       "0   Colin Kaepernick became a starting quarterback...      0  val   \n",
       "1                           Tilda Swinton is a vegan.      0  val   \n",
       "2      Fox 2000 Pictures released the film Soul Food.      1  val   \n",
       "4   Telemundo is a English-language television net...      0  val   \n",
       "6                There is a capital called Mogadishu.      1  val   \n",
       "7              Savages was exclusively a German film.      0  val   \n",
       "9                Andrew Kevin Walker is only Chinese.      0  val   \n",
       "10  Shooter is about an expert marksman who tries ...      0  val   \n",
       "13       Murda Beatz's real name is Marshall Mathers.      0  val   \n",
       "14         Nicholas Brody is a character on Homeland.      1  val   \n",
       "\n",
       "   dataset_origin  prediction  \n",
       "0           Fever           0  \n",
       "1           Fever           0  \n",
       "2           Fever           1  \n",
       "4           Fever           0  \n",
       "6           Fever           0  \n",
       "7           Fever           1  \n",
       "9           Fever           0  \n",
       "10          Fever           1  \n",
       "13          Fever           0  \n",
       "14          Fever           0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eeb76a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6277814136125655"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "correct_predictions/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b7280a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = sum([1 for i in range(len(labels)) if labels[i] == predicted_labels[i] and predicted_labels[i] == 1]) \n",
    "fp = sum([1 for i in range(len(labels)) if labels[i] != predicted_labels[i] and predicted_labels[i] == 1]) \n",
    "tn = sum([1 for i in range(len(labels)) if labels[i] == predicted_labels[i] and predicted_labels[i] == 0]) \n",
    "fn = sum([1 for i in range(len(labels)) if labels[i] != predicted_labels[i] and predicted_labels[i] == 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "77683904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40016433853738703\n"
     ]
    }
   ],
   "source": [
    "precision = tp/(tp+fp)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "500d7347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23966535433070865\n"
     ]
    }
   ],
   "source": [
    "recall = tp/(tp+fn)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14b8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = train_data.iloc[0:6112]\n",
    "labels = list(new_train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c647505",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label = sum([1 for i in range(len(labels)) if labels[i] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e16c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3324607329842932"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_label/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c8fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dsgt_cleff_simpltxt_2]",
   "language": "python",
   "name": "conda-env-.conda-dsgt_cleff_simpltxt_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
